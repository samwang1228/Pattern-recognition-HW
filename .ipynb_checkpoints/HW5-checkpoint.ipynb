{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
    "\n",
    "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
    "\n",
    "This notebook was generated for TensorFlow 2.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Fundamentals of machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Generalization: The goal of machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Underfitting and overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Noisy training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Ambiguous features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Rare features and spurious correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Adding white-noise channels or all-zeros channels to MNIST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(train_images, train_labels), _ = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "\n",
    "train_images_with_noise_channels = np.concatenate(\n",
    "    [train_images, np.random.random((len(train_images), 784))], axis=1)\n",
    "\n",
    "train_images_with_zeros_channels = np.concatenate(\n",
    "    [train_images, np.zeros((len(train_images), 784))], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training the same model on MNIST data with noise channels or all-zero channels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 4s 4ms/step - loss: 1.0776 - accuracy: 0.6946 - val_loss: 0.2846 - val_accuracy: 0.9171\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2747 - accuracy: 0.9139 - val_loss: 0.2090 - val_accuracy: 0.9348\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1769 - accuracy: 0.9429 - val_loss: 0.1901 - val_accuracy: 0.9406\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1206 - accuracy: 0.9624 - val_loss: 0.1918 - val_accuracy: 0.9426\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0860 - accuracy: 0.9728 - val_loss: 0.1285 - val_accuracy: 0.9622\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0617 - accuracy: 0.9801 - val_loss: 0.1299 - val_accuracy: 0.9638\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0471 - accuracy: 0.9844 - val_loss: 0.1298 - val_accuracy: 0.9646\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0344 - accuracy: 0.9885 - val_loss: 0.1495 - val_accuracy: 0.9617\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0283 - accuracy: 0.9910 - val_loss: 0.1398 - val_accuracy: 0.9657\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0209 - accuracy: 0.9934 - val_loss: 0.1268 - val_accuracy: 0.9697\n",
      "Epoch 1/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4747 - accuracy: 0.8626 - val_loss: 0.1527 - val_accuracy: 0.9572\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1300 - accuracy: 0.9620 - val_loss: 0.1065 - val_accuracy: 0.9676\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0804 - accuracy: 0.9770 - val_loss: 0.0873 - val_accuracy: 0.9752\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0563 - accuracy: 0.9830 - val_loss: 0.0882 - val_accuracy: 0.9746\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0394 - accuracy: 0.9886 - val_loss: 0.0772 - val_accuracy: 0.9786\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0295 - accuracy: 0.9912 - val_loss: 0.0777 - val_accuracy: 0.9772\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0229 - accuracy: 0.9935 - val_loss: 0.0770 - val_accuracy: 0.9798\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0180 - accuracy: 0.9954 - val_loss: 0.0819 - val_accuracy: 0.9784\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 0.0874 - val_accuracy: 0.9777\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0094 - accuracy: 0.9975 - val_loss: 0.0866 - val_accuracy: 0.9783\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def get_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(512, activation=\"relu\"),\n",
    "        layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "    model.compile(optimizer=\"rmsprop\",\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "history_noise = model.fit(\n",
    "    train_images_with_noise_channels, train_labels,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)\n",
    "\n",
    "model = get_model()\n",
    "history_zeros = model.fit(\n",
    "    train_images_with_zeros_channels, train_labels,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Plotting a validation accuracy comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x22589d157c0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "val_acc_noise = history_noise.history[\"val_accuracy\"]\n",
    "val_acc_zeros = history_zeros.history[\"val_accuracy\"]\n",
    "epochs = range(1, 11)\n",
    "plt.plot(epochs, val_acc_noise, \"b-\",\n",
    "         label=\"Validation accuracy with noise channels\")\n",
    "plt.plot(epochs, val_acc_zeros, \"b--\",\n",
    "         label=\"Validation accuracy with zeros channels\")\n",
    "plt.title(\"Effect of noise channels on validation accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The nature of generalization in deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Fitting a MNIST model with randomly shuffled labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3359 - accuracy: 0.1034 - val_loss: 2.3058 - val_accuracy: 0.0992\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.2984 - accuracy: 0.1176 - val_loss: 2.3124 - val_accuracy: 0.1016\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.2891 - accuracy: 0.1279 - val_loss: 2.3176 - val_accuracy: 0.1073\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.2743 - accuracy: 0.1461 - val_loss: 2.3252 - val_accuracy: 0.1022\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.2560 - accuracy: 0.1584 - val_loss: 2.3341 - val_accuracy: 0.1066\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.2329 - accuracy: 0.1707 - val_loss: 2.3509 - val_accuracy: 0.0978\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.2105 - accuracy: 0.1884 - val_loss: 2.3699 - val_accuracy: 0.1020\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.1810 - accuracy: 0.2017 - val_loss: 2.3847 - val_accuracy: 0.0967\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.1474 - accuracy: 0.2185 - val_loss: 2.3996 - val_accuracy: 0.1026\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.1240 - accuracy: 0.2361 - val_loss: 2.4254 - val_accuracy: 0.0950\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.0875 - accuracy: 0.2525 - val_loss: 2.4486 - val_accuracy: 0.1011\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.0534 - accuracy: 0.2690 - val_loss: 2.4748 - val_accuracy: 0.0984\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.0193 - accuracy: 0.2817 - val_loss: 2.5057 - val_accuracy: 0.0985\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.9876 - accuracy: 0.2962 - val_loss: 2.5435 - val_accuracy: 0.0994\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.9431 - accuracy: 0.3172 - val_loss: 2.5630 - val_accuracy: 0.1013\n",
      "Epoch 16/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.9120 - accuracy: 0.3306 - val_loss: 2.5840 - val_accuracy: 0.0978\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.8795 - accuracy: 0.3398 - val_loss: 2.6386 - val_accuracy: 0.0998\n",
      "Epoch 18/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.8465 - accuracy: 0.3560 - val_loss: 2.6507 - val_accuracy: 0.0959\n",
      "Epoch 19/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.8053 - accuracy: 0.3729 - val_loss: 2.6969 - val_accuracy: 0.0988\n",
      "Epoch 20/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.7839 - accuracy: 0.3777 - val_loss: 2.7253 - val_accuracy: 0.0973\n",
      "Epoch 21/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.7450 - accuracy: 0.3952 - val_loss: 2.7721 - val_accuracy: 0.0996\n",
      "Epoch 22/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.7054 - accuracy: 0.4090 - val_loss: 2.8090 - val_accuracy: 0.0951\n",
      "Epoch 23/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.6838 - accuracy: 0.4171 - val_loss: 2.8301 - val_accuracy: 0.0983\n",
      "Epoch 24/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.6519 - accuracy: 0.4291 - val_loss: 2.8649 - val_accuracy: 0.1042\n",
      "Epoch 25/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.6194 - accuracy: 0.4417 - val_loss: 2.9176 - val_accuracy: 0.0976\n",
      "Epoch 26/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.5907 - accuracy: 0.4559 - val_loss: 2.9520 - val_accuracy: 0.0945\n",
      "Epoch 27/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.5724 - accuracy: 0.4581 - val_loss: 3.0241 - val_accuracy: 0.0983\n",
      "Epoch 28/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.5404 - accuracy: 0.4701 - val_loss: 3.0647 - val_accuracy: 0.1034\n",
      "Epoch 29/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.5180 - accuracy: 0.4833 - val_loss: 3.0873 - val_accuracy: 0.0980\n",
      "Epoch 30/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.4882 - accuracy: 0.4942 - val_loss: 3.1386 - val_accuracy: 0.0948\n",
      "Epoch 31/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.4642 - accuracy: 0.5023 - val_loss: 3.1779 - val_accuracy: 0.1018\n",
      "Epoch 32/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.4375 - accuracy: 0.5110 - val_loss: 3.2072 - val_accuracy: 0.1020\n",
      "Epoch 33/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.4216 - accuracy: 0.5144 - val_loss: 3.2578 - val_accuracy: 0.1031\n",
      "Epoch 34/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.3941 - accuracy: 0.5254 - val_loss: 3.3223 - val_accuracy: 0.1027\n",
      "Epoch 35/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.3655 - accuracy: 0.5351 - val_loss: 3.3480 - val_accuracy: 0.1014\n",
      "Epoch 36/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.3439 - accuracy: 0.5441 - val_loss: 3.4076 - val_accuracy: 0.1000\n",
      "Epoch 37/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.3195 - accuracy: 0.5570 - val_loss: 3.4411 - val_accuracy: 0.1005\n",
      "Epoch 38/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.3084 - accuracy: 0.5597 - val_loss: 3.5089 - val_accuracy: 0.1009\n",
      "Epoch 39/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.2772 - accuracy: 0.5672 - val_loss: 3.5427 - val_accuracy: 0.1011\n",
      "Epoch 40/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.2589 - accuracy: 0.5737 - val_loss: 3.6001 - val_accuracy: 0.1051\n",
      "Epoch 41/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.2357 - accuracy: 0.5833 - val_loss: 3.6243 - val_accuracy: 0.0998\n",
      "Epoch 42/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.2184 - accuracy: 0.5908 - val_loss: 3.6947 - val_accuracy: 0.1004\n",
      "Epoch 43/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.2035 - accuracy: 0.5953 - val_loss: 3.7481 - val_accuracy: 0.1002\n",
      "Epoch 44/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.1809 - accuracy: 0.6039 - val_loss: 3.8064 - val_accuracy: 0.0983\n",
      "Epoch 45/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.1578 - accuracy: 0.6117 - val_loss: 3.8301 - val_accuracy: 0.1023\n",
      "Epoch 46/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.1460 - accuracy: 0.6171 - val_loss: 3.8960 - val_accuracy: 0.1031\n",
      "Epoch 47/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.1314 - accuracy: 0.6213 - val_loss: 3.9645 - val_accuracy: 0.1013\n",
      "Epoch 48/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.1011 - accuracy: 0.6337 - val_loss: 4.0202 - val_accuracy: 0.1034\n",
      "Epoch 49/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.0830 - accuracy: 0.6379 - val_loss: 4.0194 - val_accuracy: 0.1004\n",
      "Epoch 50/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.0788 - accuracy: 0.6408 - val_loss: 4.0944 - val_accuracy: 0.1004\n",
      "Epoch 51/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.0620 - accuracy: 0.6474 - val_loss: 4.1800 - val_accuracy: 0.1013\n",
      "Epoch 52/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.0431 - accuracy: 0.6522 - val_loss: 4.2096 - val_accuracy: 0.1019\n",
      "Epoch 53/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.0221 - accuracy: 0.6618 - val_loss: 4.3020 - val_accuracy: 0.1030\n",
      "Epoch 54/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.0071 - accuracy: 0.6676 - val_loss: 4.2984 - val_accuracy: 0.1018\n",
      "Epoch 55/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.9902 - accuracy: 0.6714 - val_loss: 4.3853 - val_accuracy: 0.1023\n",
      "Epoch 56/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.9801 - accuracy: 0.6778 - val_loss: 4.4541 - val_accuracy: 0.1002\n",
      "Epoch 57/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.9611 - accuracy: 0.6827 - val_loss: 4.4745 - val_accuracy: 0.1017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.9438 - accuracy: 0.6906 - val_loss: 4.5647 - val_accuracy: 0.1027\n",
      "Epoch 59/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.9319 - accuracy: 0.6924 - val_loss: 4.6247 - val_accuracy: 0.1003\n",
      "Epoch 60/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.9175 - accuracy: 0.6975 - val_loss: 4.6878 - val_accuracy: 0.1014\n",
      "Epoch 61/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.9096 - accuracy: 0.7021 - val_loss: 4.7481 - val_accuracy: 0.0981\n",
      "Epoch 62/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.8943 - accuracy: 0.7046 - val_loss: 4.7649 - val_accuracy: 0.1013\n",
      "Epoch 63/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.8803 - accuracy: 0.7108 - val_loss: 4.8408 - val_accuracy: 0.1003\n",
      "Epoch 64/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.8675 - accuracy: 0.7160 - val_loss: 4.8979 - val_accuracy: 0.0978\n",
      "Epoch 65/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.8457 - accuracy: 0.7191 - val_loss: 4.9824 - val_accuracy: 0.1005\n",
      "Epoch 66/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.8425 - accuracy: 0.7241 - val_loss: 5.0256 - val_accuracy: 0.1034\n",
      "Epoch 67/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.8285 - accuracy: 0.7313 - val_loss: 5.0718 - val_accuracy: 0.1016\n",
      "Epoch 68/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.8132 - accuracy: 0.7348 - val_loss: 5.1348 - val_accuracy: 0.1021\n",
      "Epoch 69/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.8052 - accuracy: 0.7358 - val_loss: 5.1844 - val_accuracy: 0.1031\n",
      "Epoch 70/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.7935 - accuracy: 0.7408 - val_loss: 5.2440 - val_accuracy: 0.1022\n",
      "Epoch 71/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.7920 - accuracy: 0.7434 - val_loss: 5.3496 - val_accuracy: 0.1003\n",
      "Epoch 72/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.7607 - accuracy: 0.7520 - val_loss: 5.4044 - val_accuracy: 0.1013\n",
      "Epoch 73/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.7574 - accuracy: 0.7518 - val_loss: 5.4540 - val_accuracy: 0.0995\n",
      "Epoch 74/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.7492 - accuracy: 0.7564 - val_loss: 5.4885 - val_accuracy: 0.1009\n",
      "Epoch 75/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.7353 - accuracy: 0.7608 - val_loss: 5.5278 - val_accuracy: 0.1018\n",
      "Epoch 76/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.7272 - accuracy: 0.7647 - val_loss: 5.6047 - val_accuracy: 0.0995\n",
      "Epoch 77/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.7089 - accuracy: 0.7689 - val_loss: 5.7058 - val_accuracy: 0.0980\n",
      "Epoch 78/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.7062 - accuracy: 0.7702 - val_loss: 5.7420 - val_accuracy: 0.1007\n",
      "Epoch 79/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6977 - accuracy: 0.7767 - val_loss: 5.8200 - val_accuracy: 0.0988\n",
      "Epoch 80/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6897 - accuracy: 0.7757 - val_loss: 5.8946 - val_accuracy: 0.0996\n",
      "Epoch 81/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6766 - accuracy: 0.7835 - val_loss: 5.9162 - val_accuracy: 0.0984\n",
      "Epoch 82/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6719 - accuracy: 0.7844 - val_loss: 5.9961 - val_accuracy: 0.1007\n",
      "Epoch 83/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6543 - accuracy: 0.7889 - val_loss: 6.0846 - val_accuracy: 0.1013\n",
      "Epoch 84/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6538 - accuracy: 0.7890 - val_loss: 6.1318 - val_accuracy: 0.1009\n",
      "Epoch 85/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6313 - accuracy: 0.7978 - val_loss: 6.2074 - val_accuracy: 0.0988\n",
      "Epoch 86/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6308 - accuracy: 0.7979 - val_loss: 6.2352 - val_accuracy: 0.0998\n",
      "Epoch 87/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6191 - accuracy: 0.8000 - val_loss: 6.2936 - val_accuracy: 0.1042\n",
      "Epoch 88/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6147 - accuracy: 0.8010 - val_loss: 6.4289 - val_accuracy: 0.0991\n",
      "Epoch 89/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6112 - accuracy: 0.8034 - val_loss: 6.4678 - val_accuracy: 0.0988\n",
      "Epoch 90/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5930 - accuracy: 0.8102 - val_loss: 6.5031 - val_accuracy: 0.1018\n",
      "Epoch 91/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5880 - accuracy: 0.8120 - val_loss: 6.5595 - val_accuracy: 0.1002\n",
      "Epoch 92/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5739 - accuracy: 0.8180 - val_loss: 6.6564 - val_accuracy: 0.1039\n",
      "Epoch 93/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5712 - accuracy: 0.8159 - val_loss: 6.6985 - val_accuracy: 0.1021\n",
      "Epoch 94/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5682 - accuracy: 0.8164 - val_loss: 6.8192 - val_accuracy: 0.1025\n",
      "Epoch 95/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5614 - accuracy: 0.8198 - val_loss: 6.8325 - val_accuracy: 0.0995\n",
      "Epoch 96/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5528 - accuracy: 0.8224 - val_loss: 6.8872 - val_accuracy: 0.0993\n",
      "Epoch 97/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5437 - accuracy: 0.8272 - val_loss: 6.9905 - val_accuracy: 0.1008\n",
      "Epoch 98/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5368 - accuracy: 0.8295 - val_loss: 7.0355 - val_accuracy: 0.1023\n",
      "Epoch 99/100\n",
      " 58/375 [===>..........................] - ETA: 0s - loss: 0.5069 - accuracy: 0.8392"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), _ = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "\n",
    "random_train_labels = train_labels[:]\n",
    "np.random.shuffle(random_train_labels)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, random_train_labels,\n",
    "          epochs=100,\n",
    "          batch_size=128,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The manifold hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Interpolation as a source of generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Why deep learning works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Training data is paramount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Evaluating machine-learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Training, validation, and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Simple hold-out validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### K-fold validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Iterated K-fold validation with shuffling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Beating a common-sense baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Things to keep in mind about model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Improving model fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Tuning key gradient descent parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a MNIST model with an incorrectly high learning rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), _ = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(1.),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          batch_size=128,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The same model with a more appropriate learning rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(1e-2),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          batch_size=128,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Leveraging better architecture priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Increasing model capacity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple logistic regression on MNIST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([layers.Dense(10, activation=\"softmax\")])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_small_model = model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "val_loss = history_small_model.history[\"val_loss\"]\n",
    "epochs = range(1, 21)\n",
    "plt.plot(epochs, val_loss, \"b--\",\n",
    "         label=\"Validation loss\")\n",
    "plt.title(\"Effect of insufficient model capacity on validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(96, activation=\"relu\"),\n",
    "    layers.Dense(96, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_large_model = model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Improving generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Dataset curation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Using early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Regularizing your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Reducing the network's size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Original model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "(train_data, train_labels), _ = imdb.load_data(num_words=10000)\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "train_data = vectorize_sequences(train_data)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_original = model.fit(train_data, train_labels,\n",
    "                             epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Version of the model with lower capacity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(4, activation=\"relu\"),\n",
    "    layers.Dense(4, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_smaller_model = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Version of the model with higher capacity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_larger_model = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Adding weight regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Adding L2 weight regularization to the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(16,\n",
    "                 kernel_regularizer=regularizers.l2(0.002),\n",
    "                 activation=\"relu\"),\n",
    "    layers.Dense(16,\n",
    "                 kernel_regularizer=regularizers.l2(0.002),\n",
    "                 activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_l2_reg = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Different weight regularizers available in Keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "regularizers.l1(0.001)\n",
    "regularizers.l1_l2(l1=0.001, l2=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Adding dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Adding dropout to the IMDB model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_dropout = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Summary"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter05_fundamentals-of-ml.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
